# IDM-VTON Preprocessing Module

Complete preprocessing pipeline for virtual try-on feature extraction and dataset management.

## üìÇ Module Location

```
preprocessing/
‚îú‚îÄ‚îÄ __init__.py
‚îú‚îÄ‚îÄ preprocessing_pipeline.py       (555 lines) - Feature extraction
‚îú‚îÄ‚îÄ dataset_utils.py               (519 lines) - Dataset utilities
‚îî‚îÄ‚îÄ examples_preprocessing.py       (306 lines) - 7 working examples
```

## ‚ö° Quick Start

```python
from preprocessing import FeatureExtractor

# Extract features from single image pair
extractor = FeatureExtractor(gpu_id=0)
output = extractor.process('human.jpg', 'garment.jpg')

# Access features
print(output.human_keypoints)  # 18 OpenPose points
print(output.pose_image.size)  # DensePose visualization
print(output.inpaint_mask.size)  # Inpainting mask
```

## üéØ Core Features

**Extracts from each image pair:**
- Human keypoints (18 OpenPose skeleton points)
- Human parsing (19-class clothing segmentation)
- Inpainting mask (binary mask for garment region)
- Pose visualization (DensePose)
- Model-ready tensors (float16, normalized)

**Supports categories:**
- `upper_body` - Shirts, tops, jackets
- `lower_body` - Pants, skirts, shorts
- `dresses` - Full-body dresses

## üì¶ Core Classes

### FeatureExtractor
```python
extractor = FeatureExtractor(gpu_id=0, device='cuda:0')

# Single image processing
output = extractor.process(human_img, garment_img)

# Or extract features separately
keypoints = extractor.extract_keypoints(img)
parsing, _ = extractor.extract_parsing(img)
mask, _ = extractor.generate_mask(img, parsing, keypoints, category='upper_body')
pose = extractor.extract_pose_image(img)
```

### DatasetPreprocessor
```python
pp = DatasetPreprocessor(gpu_id=0)

# Preprocess VITON-HD
pp.preprocess_viton_hd('/input/VITON-HD', '/output')

# Preprocess DressCode
pp.preprocess_dresscode('/input/DressCode', '/output',
                        categories=['upper_body', 'lower_body', 'dresses'])
```

### Dataset Loaders
```python
from preprocessing import get_dataset_loader, VITONHDDataset, DressCodeDataset

# Using helper function
loader = get_dataset_loader('viton-hd', '/preprocessed', batch_size=8)

# Or create dataset directly
dataset = VITONHDDataset('/preprocessed')
dataset = DressCodeDataset('/preprocessed', category='upper_body')
```

### DatasetValidator
```python
from preprocessing import DatasetValidator

v = DatasetValidator()
results = v.validate_viton_hd('/preprocessed')
print(f"Valid: {results['valid']}, Images: {results['total_images']}")
```

## üöÄ Usage Patterns

### Pattern 1: Single Image Processing
```python
from preprocessing import FeatureExtractor

extractor = FeatureExtractor(gpu_id=0)
output = extractor.process('person.jpg', 'garment.jpg')

# Save outputs
output.pose_image.save('pose.jpg')
output.inpaint_mask.save('mask.jpg')
```

### Pattern 2: Batch Dataset Preprocessing
```python
from preprocessing import DatasetPreprocessor

pp = DatasetPreprocessor(gpu_id=0)
pp.preprocess_viton_hd('/raw/VITON-HD', '/processed')

# Output structure:
# /processed/humans/keypoints/*.json
# /processed/humans/parsing/*.npy
# /processed/humans/masks/*.jpg
# /processed/humans/poses/*.jpg
# /processed/garments/*.jpg
# /processed/garments/tensors/*.pt
```

### Pattern 3: Training Integration
```python
from preprocessing import get_dataset_loader

loader = get_dataset_loader(
    'viton-hd',
    '/preprocessed',
    batch_size=16,
    num_workers=4
)

for epoch in range(10):
    for batch in loader:
        human = batch['human']      # (16, 3, 1024, 768)
        garment = batch['garment']  # (16, 3, 1024, 768)
        pose = batch['pose']        # (16, 3, 1024, 768)
        mask = batch['mask']        # (16, 1, 1024, 768)

        # Train IDM-VTON model
```

### Pattern 4: Multi-Category Processing
```python
from preprocessing import FeatureExtractor

extractor = FeatureExtractor(gpu_id=0)

for category in ['upper_body', 'lower_body', 'dresses']:
    output = extractor.process('human.jpg', 'garment.jpg', category=category)
    output.inpaint_mask.save(f'mask_{category}.jpg')
    print(f"‚úì {category}")
```

## üéì Working Examples

Run any of 7 complete working examples:

```bash
cd /path/to/IDM-VTON
python preprocessing/examples_preprocessing.py
# Uncomment the example you want to run
```

**Examples included:**
1. Single image preprocessing
2. Batch dataset preprocessing
3. Dataset validation
4. Dataset loading & iteration
5. PyTorch DataLoader integration
6. Custom preprocessing workflow
7. Batch processing with custom output

## üìä Extracted Features

### PreprocessingOutput
```python
output.human_image          # PIL Image, 768√ó1024 RGB
output.human_keypoints      # Dict with 18 OpenPose points
output.human_parsing        # PIL Image, clothing segmentation
output.inpaint_mask         # PIL Image, binary (0/255)
output.pose_image           # PIL Image, DensePose visualization
output.garment_image        # PIL Image, 768√ó1024 RGB
output.garment_tensor       # Torch Tensor (optional, float16)
output.category             # String: 'upper_body', 'lower_body', 'dresses'
```

## üíæ Dataset Support

### VITON-HD
- 55,000+ image pairs
- Single category: upper_body
- Input structure: `image/`, `cloth/`, `image-densepose/`, `agnostic-mask/`

### DressCode
- ~25,000 images per category
- 3 categories: upper_body, lower_body, dresses
- Per-category structure with images and captions

## ‚öôÔ∏è Requirements

**Python Packages:**
```
torch >= 1.10
torchvision >= 0.11
pillow >= 8.0
numpy >= 1.20
```

**Local Packages (in repo):**
- `gradio_demo/detectron2/` - Local detectron2
- `gradio_demo/densepose/` - Local densepose
- `preprocess/openpose/` - OpenPose models
- `preprocess/humanparsing/` - Human parsing models

**Model Checkpoints:**
```
ckpt/densepose/model_final_162be9.pkl
ckpt/humanparsing/parsing_atr.onnx
ckpt/humanparsing/parsing_lip.onnx
```

## üöÄ Performance

**Speed (RTX 3090):**
- Single image: 2-3 seconds
- Batch of 8: 20-25 seconds
- VITON-HD full (55K): 2-3 hours
- DressCode per category (25K): 1-2 hours

**Memory:**
- Single image: ~2 GB VRAM
- Batch of 8: ~4-6 GB VRAM
- Image caching: ~8 GB RAM per 10K images

## üîß Troubleshooting

**Issue: "ModuleNotFoundError: No module named 'preprocess'"**
- Make sure you're in IDM-VTON root directory
- Run: `cd /path/to/IDM-VTON`

**Issue: "ModuleNotFoundError: No module named 'detectron2'"**
- Local detectron2 is in `gradio_demo/`
- Module automatically handles this - just run from root

**Issue: "FileNotFoundError: ckpt/... not found"**
- Download model checkpoints
- Ensure you're in IDM-VTON root directory

**Issue: "RuntimeError: CUDA out of memory"**
- Reduce batch size
- Use `device='cpu'` temporarily
- Set `cache_images=False` in dataset loaders

## üéì Integration with IDM-VTON

Preprocessing outputs integrate directly with IDM-VTON pipeline:

```python
from preprocessing import FeatureExtractor
from src.tryon_pipeline import StableDiffusionXLInpaintPipeline

# Extract features
extractor = FeatureExtractor(gpu_id=0)
output = extractor.process('human.jpg', 'garment.jpg')

# Use with IDM-VTON
pipe = StableDiffusionXLInpaintPipeline.from_pretrained(...)
result = pipe(
    prompt_embeds=...,
    pose_img=output.pose_image,
    cloth=output.garment_image,
    mask_image=output.inpaint_mask,
    image=output.human_image,
    ...
)
```

## üìù Module Statistics

| File | Lines | Purpose |
|------|-------|---------|
| preprocessing_pipeline.py | 555 | Feature extraction |
| dataset_utils.py | 519 | Dataset management |
| examples_preprocessing.py | 306 | Working examples |
| __init__.py | 43 | Package init |
| **Total** | **1,423** | |

## ‚úÖ API Summary

### Classes
- `FeatureExtractor` - Extract features from images
- `DatasetPreprocessor` - Batch process datasets
- `VITONHDDataset` - Load VITON-HD data
- `DressCodeDataset` - Load DressCode data
- `DatasetValidator` - Validate dataset structure
- `PreprocessingOutput` - Container for features

### Functions
- `get_dataset_loader()` - Create PyTorch DataLoader

## üìç How to Use

**Step 1: Navigate to IDM-VTON root**
```bash
cd /path/to/IDM-VTON
```

**Step 2: Import and use**
```python
from preprocessing import FeatureExtractor
extractor = FeatureExtractor(gpu_id=0)
output = extractor.process('image.jpg', 'garment.jpg')
```

**Step 3: Run examples**
```bash
python preprocessing/examples_preprocessing.py
```

## üéØ Common Tasks

**Extract from single image:**
```python
from preprocessing import FeatureExtractor
extractor = FeatureExtractor(gpu_id=0)
output = extractor.process('human.jpg', 'garment.jpg')
```

**Preprocess dataset:**
```python
from preprocessing import DatasetPreprocessor
pp = DatasetPreprocessor(gpu_id=0)
pp.preprocess_viton_hd('/input', '/output')
```

**Validate dataset:**
```python
from preprocessing import DatasetValidator
v = DatasetValidator()
results = v.validate_viton_hd('/output')
print(results)
```

**Load for training:**
```python
from preprocessing import get_dataset_loader
loader = get_dataset_loader('viton-hd', '/output', batch_size=8)
for batch in loader:
    # Use batch
    pass
```

## üìñ For More Information

See inline docstrings in:
- `preprocessing_pipeline.py` - Feature extraction API
- `dataset_utils.py` - Dataset loading API
- `examples_preprocessing.py` - Usage examples

Or check:
- `gradio_demo/app.py` - How original app uses features
- `src/tryon_pipeline.py` - IDM-VTON model integration

---

**Status:** Production Ready ‚úÖ
**Version:** 1.0.0
**Last Updated:** 2025-11-13
